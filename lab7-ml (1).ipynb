{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31bc523e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9949494949494949\n",
      "Predicted Class: ['5G']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "path = \"C:\\\\Users\\\\adity\\\\Downloads\\\\signal_metrics.xlsx\"\n",
    "df = pd.read_excel(path)\n",
    "\n",
    "# Assuming 'Network Type' is the column you want to predict (replace it with your actual target column)\n",
    "target_column = 'Network Type'\n",
    "\n",
    "# Select relevant features (assuming all numeric columns are features)\n",
    "features = df.drop(['Timestamp', 'Locality', 'Network Type'], axis=1)\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = features\n",
    "y = df[target_column]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an SVM classifier\n",
    "clf = SVC()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Test the accuracy on the test set\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Example of classifying a test vector\n",
    "# Replace 'test_vector' with an actual feature vector from your test set\n",
    "test_vector = X_test.iloc[0].values.reshape(1, -1)  # Taking the first row as an example\n",
    "predicted_class = clf.predict(test_vector)\n",
    "print(\"Predicted Class:\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40ef0ff7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'Timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m clf \u001b[38;5;241m=\u001b[39m SVC()\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Train the classifier on the training data\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Get the support vectors\u001b[39;00m\n\u001b[0;32m     42\u001b[0m support_vectors \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39msupport_vectors_\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:190\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    188\u001b[0m     check_consistent_length(X, y)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    191\u001b[0m         X,\n\u001b[0;32m    192\u001b[0m         y,\n\u001b[0;32m    193\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64,\n\u001b[0;32m    194\u001b[0m         order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    195\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    196\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    197\u001b[0m     )\n\u001b[0;32m    199\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_targets(y)\n\u001b[0;32m    201\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[0;32m    202\u001b[0m     [] \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[0;32m    203\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1146\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1141\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1143\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1144\u001b[0m     )\n\u001b[1;32m-> 1146\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1147\u001b[0m     X,\n\u001b[0;32m   1148\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1149\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1150\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1151\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1152\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1153\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1154\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1155\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1156\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1157\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1158\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1159\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1160\u001b[0m )\n\u001b[0;32m   1162\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1164\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    913\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 915\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    917\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    918\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    919\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'Timestamp'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Load the dataset\n",
    "path = \"C:\\\\Users\\\\adity\\\\Downloads\\\\signal_metrics.xlsx\"\n",
    "df = pd.read_excel(path)\n",
    "\n",
    "# Assuming 'Network Type' is the column you want to predict (replace it with your actual target column)\n",
    "target_column = 'Network Type'\n",
    "\n",
    "# Select relevant features (assuming all numeric columns are features)\n",
    "features = df.drop(['Timestamp', 'Locality', 'Network Type'], axis=1)\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = features\n",
    "y = df[target_column]\n",
    "\n",
    "# Select two classes for this exercise (you can replace these with your actual classes)\n",
    "class_1 = '3G'\n",
    "class_2 = '4G'\n",
    "\n",
    "# Filter the dataset for the selected classes\n",
    "selected_classes_df = df[(y == class_1) | (y == class_2)]\n",
    "\n",
    "# Split the dataset into training and testing sets for the selected classes\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    selected_classes_df.drop(target_column, axis=1),\n",
    "    selected_classes_df[target_column],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create an SVM classifier\n",
    "clf = SVC()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get the support vectors\n",
    "support_vectors = clf.support_vectors_\n",
    "print(\"Support Vectors:\\n\", support_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dabbfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vectors:\n",
      " [[ 25.50820575  85.04452352 -81.87080395   0.           2.67951393\n",
      "  100.14517117   0.           0.           0.        ]\n",
      " [ 25.74157839  85.10993045 -94.23587879   0.           2.50711923\n",
      "  100.8523971    0.           0.           0.        ]\n",
      " [ 25.6622262   85.17863024 -77.05927216   0.           2.28162352\n",
      "  199.85246449   0.           0.           0.        ]\n",
      " [ 25.47256397  85.09940818 -81.6766636    0.           1.28079693\n",
      "  100.00089656   0.           0.           0.        ]\n",
      " [ 25.6789034   85.23554629 -80.53821401   0.           2.76914469\n",
      "  100.02334951   0.           0.           0.        ]\n",
      " [ 25.63458066  85.31036996 -87.0589786    0.           2.77180476\n",
      "  100.0307075    0.           0.           0.        ]\n",
      " [ 25.56914994  85.03117616 -80.83425748   0.           5.86313296\n",
      "   99.1774723  -78.46794326 -86.0803605  -79.46457343]\n",
      " [ 25.62924079  85.25110615 -79.63337651   0.           7.56724103\n",
      "   93.82124009 -76.01484939 -86.44516223 -80.37899289]\n",
      " [ 25.46228819  85.23099411 -78.74126661   0.           5.05394765\n",
      "   61.02337136 -76.38738628 -88.44806032 -75.90696017]\n",
      " [ 25.4629501   85.09027219 -78.54834059   0.           5.44435178\n",
      "   95.61425952 -75.58124457 -86.49970414 -77.42732547]\n",
      " [ 25.45918763  85.13343574 -78.70135841   0.           4.03693898\n",
      "   73.33283752 -75.79856813 -85.57995386 -79.23621501]]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Load the dataset\n",
    "path = \"C:\\\\Users\\\\adity\\\\Downloads\\\\signal_metrics.xlsx\"\n",
    "df = pd.read_excel(path)\n",
    "\n",
    "# Assuming 'Network Type' is the column you want to predict (replace it with your actual target column)\n",
    "target_column = 'Network Type'\n",
    "\n",
    "# Select relevant features (assuming all numeric columns are features)\n",
    "numeric_columns = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Ensure 'Network Type' is not dropped\n",
    "if target_column in numeric_columns:\n",
    "    numeric_columns = numeric_columns.drop(target_column)\n",
    "\n",
    "# Features\n",
    "features = df[numeric_columns]\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = features\n",
    "y = df[target_column]\n",
    "\n",
    "# Select two classes for this exercise (you can replace these with your actual classes)\n",
    "class_1 = '3G'\n",
    "class_2 = '4G'\n",
    "\n",
    "# Filter the dataset for the selected classes\n",
    "selected_classes_df = df[(y == class_1) | (y == class_2)]\n",
    "\n",
    "# Split the dataset into training and testing sets for the selected classes\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    selected_classes_df[numeric_columns],\n",
    "    selected_classes_df[target_column],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create an SVM classifier\n",
    "clf = SVC()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get the support vectors\n",
    "support_vectors = clf.support_vectors_\n",
    "print(\"Support Vectors:\\n\", support_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df854c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Labels:\n",
      " ['4G' '4G' '3G' ... '3G' '4G' '4G']\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "path = \"C:\\\\Users\\\\adity\\\\Downloads\\\\signal_metrics.xlsx\"\n",
    "df = pd.read_excel(path)\n",
    "\n",
    "# Assuming 'Network Type' is the column you want to predict (replace it with your actual target column)\n",
    "target_column = 'Network Type'\n",
    "\n",
    "# Select relevant features (assuming all numeric columns are features)\n",
    "numeric_columns = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Ensure 'Network Type' is not dropped\n",
    "if target_column in numeric_columns:\n",
    "    numeric_columns = numeric_columns.drop(target_column)\n",
    "\n",
    "# Features\n",
    "features = df[numeric_columns]\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = features\n",
    "y = df[target_column]\n",
    "\n",
    "# Select two classes for this exercise (you can replace these with your actual classes)\n",
    "class_1 = '3G'\n",
    "class_2 = '4G'\n",
    "\n",
    "# Filter the dataset for the selected classes\n",
    "selected_classes_df = df[(y == class_1) | (y == class_2)]\n",
    "\n",
    "# Split the dataset into training and testing sets for the selected classes\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    selected_classes_df[numeric_columns],\n",
    "    selected_classes_df[target_column],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create an SVM classifier\n",
    "clf = SVC()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Use the predict function to obtain predicted class labels for the test set\n",
    "predicted_labels = clf.predict(X_test)\n",
    "\n",
    "# Display the predicted labels\n",
    "print(\"Predicted Labels:\\n\", predicted_labels)\n",
    "\n",
    "# Test the accuracy of the SVM\n",
    "accuracy = accuracy_score(y_test, predicted_labels)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15e349b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with linear kernel: 1.0\n",
      "Accuracy with poly kernel: 1.0\n",
      "Accuracy with rbf kernel: 1.0\n",
      "Accuracy with sigmoid kernel: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "path = \"C:\\\\Users\\\\adity\\\\Downloads\\\\signal_metrics.xlsx\"\n",
    "df = pd.read_excel(path)\n",
    "\n",
    "# Assuming 'Network Type' is the column you want to predict (replace it with your actual target column)\n",
    "target_column = 'Network Type'\n",
    "\n",
    "# Select relevant features (assuming all numeric columns are features)\n",
    "numeric_columns = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Ensure 'Network Type' is not dropped\n",
    "if target_column in numeric_columns:\n",
    "    numeric_columns = numeric_columns.drop(target_column)\n",
    "\n",
    "# Features\n",
    "features = df[numeric_columns]\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = features\n",
    "y = df[target_column]\n",
    "\n",
    "# Select two classes for this exercise (you can replace these with your actual classes)\n",
    "class_1 = '3G'\n",
    "class_2 = '4G'\n",
    "\n",
    "# Filter the dataset for the selected classes\n",
    "selected_classes_df = df[(y == class_1) | (y == class_2)]\n",
    "\n",
    "# Split the dataset into training and testing sets for the selected classes\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    selected_classes_df[numeric_columns],\n",
    "    selected_classes_df[target_column],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Experiment with different kernel functions\n",
    "kernel_functions = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "for kernel in kernel_functions:\n",
    "    # Create an SVM classifier with the specified kernel\n",
    "    clf = SVC(kernel=kernel)\n",
    "\n",
    "    # Train the classifier on the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Use the predict function to obtain predicted class labels for the test set\n",
    "    predicted_labels = clf.predict(X_test)\n",
    "\n",
    "    # Calculate and display the accuracy\n",
    "    accuracy = accuracy_score(y_test, predicted_labels)\n",
    "    print(f\"Accuracy with {kernel} kernel:\", accuracy)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8344c711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
